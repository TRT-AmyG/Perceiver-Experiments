{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cifar10 (/home/amy/.cache/huggingface/datasets/cifar10/plain_text/1.0.0/447d6ec4733dddd1ce3bb577c7166b986eaa4c538dcd9e805ba61f35674a9de4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ae08aa82464037a77feb47070bb7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load cifar10 (only small portion for demonstration purposes) \n",
    "train_ds, test_ds = load_dataset('cifar10', split=['train[:500]', 'test[:200]'])\n",
    "# split up training into training + validation\n",
    "splits = train_ds.train_test_split(test_size=0.1)\n",
    "train_ds = splits['train']\n",
    "val_ds = splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}\n",
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n"
     ]
    }
   ],
   "source": [
    "id2label = {idx:label for idx,label in enumerate(train_ds.features['label'].names)}\n",
    "label2id = {label:idx for idx, label in id2label.items()}\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 20:53:47.334928: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-01 20:53:47.463795: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-01 20:53:49.713222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/amy/.local/lib/python3.10/site-packages/transformers/models/perceiver/feature_extraction_perceiver.py:28: FutureWarning: The class PerceiverFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use PerceiverImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import PerceiverFeatureExtractor\n",
    "\n",
    "feature_extractor = PerceiverFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_images(examples):\n",
    "    examples['pixel_values'] = feature_extractor(examples['img'], return_tensors=\"pt\").pixel_values\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the transforms\n",
    "train_ds.set_transform(preprocess_images)\n",
    "val_ds.set_transform(preprocess_images)\n",
    "test_ds.set_transform(preprocess_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F4480F49900>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F4480F494B0>],\n",
       " 'label': [4, 9],\n",
       " 'pixel_values': tensor([[[[ 0.0569,  0.0569,  0.0569,  ..., -0.1314, -0.1314, -0.1314],\n",
       "           [ 0.0569,  0.0569,  0.0569,  ..., -0.1314, -0.1314, -0.1314],\n",
       "           [ 0.0569,  0.0569,  0.0569,  ..., -0.1486, -0.1486, -0.1486],\n",
       "           ...,\n",
       "           [ 1.2557,  1.2557,  1.2557,  ...,  0.0912,  0.0912,  0.0912],\n",
       "           [ 1.2557,  1.2557,  1.2557,  ...,  0.0912,  0.0912,  0.0912],\n",
       "           [ 1.2557,  1.2557,  1.2557,  ...,  0.0912,  0.0912,  0.0912]],\n",
       " \n",
       "          [[ 0.3277,  0.3277,  0.3277,  ...,  0.1877,  0.1877,  0.1877],\n",
       "           [ 0.3277,  0.3277,  0.3277,  ...,  0.1702,  0.1702,  0.1702],\n",
       "           [ 0.3277,  0.3277,  0.3277,  ...,  0.1702,  0.1702,  0.1702],\n",
       "           ...,\n",
       "           [ 1.4482,  1.4482,  1.4307,  ...,  0.3102,  0.3102,  0.3102],\n",
       "           [ 1.4482,  1.4482,  1.4307,  ...,  0.3102,  0.3102,  0.3102],\n",
       "           [ 1.4482,  1.4482,  1.4307,  ...,  0.3102,  0.3102,  0.3102]],\n",
       " \n",
       "          [[ 0.3393,  0.3393,  0.3393,  ...,  0.3045,  0.3045,  0.3045],\n",
       "           [ 0.3393,  0.3393,  0.3393,  ...,  0.3045,  0.3045,  0.3045],\n",
       "           [ 0.3393,  0.3393,  0.3393,  ...,  0.2871,  0.2871,  0.2871],\n",
       "           ...,\n",
       "           [ 1.5245,  1.5245,  1.5245,  ...,  0.3568,  0.3568,  0.3568],\n",
       "           [ 1.5245,  1.5245,  1.5245,  ...,  0.3568,  0.3568,  0.3742],\n",
       "           [ 1.5071,  1.5071,  1.5245,  ...,  0.3568,  0.3568,  0.3742]]],\n",
       " \n",
       " \n",
       "         [[[ 0.9303,  0.9303,  0.9303,  ...,  0.8789,  0.8789,  0.8789],\n",
       "           [ 0.9474,  0.9474,  0.9474,  ...,  0.8789,  0.8789,  0.8789],\n",
       "           [ 0.9646,  0.9646,  0.9646,  ...,  0.8961,  0.8961,  0.8961],\n",
       "           ...,\n",
       "           [-0.1828, -0.1828, -0.1828,  ..., -0.4568, -0.4568, -0.4568],\n",
       "           [-0.1828, -0.1828, -0.1828,  ..., -0.4568, -0.4568, -0.4568],\n",
       "           [-0.1828, -0.1828, -0.1828,  ..., -0.4568, -0.4568, -0.4568]],\n",
       " \n",
       "          [[ 1.3957,  1.3957,  1.4132,  ...,  1.3256,  1.3256,  1.3256],\n",
       "           [ 1.4132,  1.4132,  1.4307,  ...,  1.3256,  1.3256,  1.3256],\n",
       "           [ 1.4132,  1.4132,  1.4307,  ...,  1.3256,  1.3256,  1.3256],\n",
       "           ...,\n",
       "           [ 0.0301,  0.0301,  0.0301,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.0301,  0.0301,  0.0301,  ..., -0.2500, -0.2500, -0.2500],\n",
       "           [ 0.0301,  0.0301,  0.0301,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[ 1.5594,  1.5594,  1.5594,  ...,  2.0300,  2.0474,  2.0474],\n",
       "           [ 1.5594,  1.5594,  1.5594,  ...,  2.0300,  2.0474,  2.0474],\n",
       "           [ 1.5594,  1.5594,  1.5594,  ...,  2.0300,  2.0474,  2.0474],\n",
       "           ...,\n",
       "           [ 0.1128,  0.1128,  0.1128,  ..., -0.0267, -0.0092, -0.0092],\n",
       "           [ 0.1128,  0.1128,  0.1128,  ..., -0.0267, -0.0092, -0.0092],\n",
       "           [ 0.1128,  0.1128,  0.1128,  ..., -0.0267, -0.0092, -0.0092]]]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "train_batch_size = 2\n",
    "eval_batch_size = 2\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, shuffle=True, collate_fn=collate_fn, batch_size=train_batch_size)\n",
    "val_dataloader = DataLoader(val_ds, collate_fn=collate_fn, batch_size=eval_batch_size)\n",
    "test_dataloader = DataLoader(test_ds, collate_fn=collate_fn, batch_size=eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values torch.Size([2, 3, 224, 224])\n",
      "labels torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "for k,v in batch.items():\n",
    "  if isinstance(v, torch.Tensor):\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert batch['pixel_values'].shape == (train_batch_size, 3, 224, 224)\n",
    "assert batch['labels'].shape == (train_batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(val_dataloader))['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PerceiverForImageClassificationLearned were not initialized from the model checkpoint at deepmind/vision-perceiver-learned and are newly initialized because the shapes did not match:\n",
      "- perceiver.decoder.decoder.final_layer.weight: found shape torch.Size([1000, 1024]) in the checkpoint and torch.Size([10, 1024]) in the model instantiated\n",
      "- perceiver.decoder.decoder.final_layer.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PerceiverForImageClassificationLearned(\n",
       "  (perceiver): PerceiverModel(\n",
       "    (input_preprocessor): PerceiverImagePreprocessor(\n",
       "      (convnet_1x1): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (position_embeddings): PerceiverTrainablePositionEncoding()\n",
       "      (positions_projection): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (conv_after_patches): Identity()\n",
       "    )\n",
       "    (embeddings): PerceiverEmbeddings()\n",
       "    (encoder): PerceiverEncoder(\n",
       "      (cross_attention): PerceiverLayer(\n",
       "        (attention): PerceiverAttention(\n",
       "          (self): PerceiverSelfAttention(\n",
       "            (layernorm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (layernorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (query): Linear(in_features=1024, out_features=512, bias=True)\n",
       "            (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): PerceiverSelfOutput(\n",
       "            (dense): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): PerceiverMLP(\n",
       "          (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "          (dense2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (self_attends): ModuleList(\n",
       "        (0-5): 6 x PerceiverLayer(\n",
       "          (attention): PerceiverAttention(\n",
       "            (self): PerceiverSelfAttention(\n",
       "              (layernorm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm2): Identity()\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): PerceiverSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): PerceiverMLP(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (dense2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): PerceiverClassificationDecoder(\n",
       "      (decoder): PerceiverBasicDecoder(\n",
       "        (output_position_encodings): PerceiverTrainablePositionEncoding()\n",
       "        (positions_projection): Identity()\n",
       "        (decoding_cross_attention): PerceiverLayer(\n",
       "          (attention): PerceiverAttention(\n",
       "            (self): PerceiverSelfAttention(\n",
       "              (layernorm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): PerceiverSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): PerceiverMLP(\n",
       "            (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (dense2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (final_layer): Linear(in_features=1024, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PerceiverForImageClassificationLearned \n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = PerceiverForImageClassificationLearned.from_pretrained(\"deepmind/vision-perceiver-learned\",\n",
    "                                                               num_labels=10,\n",
    "                                                               id2label=id2label,\n",
    "                                                               label2id=label2id,\n",
    "                                                               ignore_mismatched_sizes=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amy/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64431f21baef43199048511db48f10c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.264371395111084, Accuracy: 0.0\n",
      "Loss: 2.222069025039673, Accuracy: 0.5\n",
      "Loss: 2.3770434856414795, Accuracy: 0.0\n",
      "Loss: 2.4273457527160645, Accuracy: 0.0\n",
      "Loss: 2.0911569595336914, Accuracy: 0.5\n",
      "Loss: 2.266533851623535, Accuracy: 0.0\n",
      "Loss: 2.263072967529297, Accuracy: 0.0\n",
      "Loss: 2.637988328933716, Accuracy: 0.0\n",
      "Loss: 2.1883111000061035, Accuracy: 0.0\n",
      "Loss: 2.240454912185669, Accuracy: 0.5\n",
      "Loss: 2.4389538764953613, Accuracy: 0.0\n",
      "Loss: 2.6921257972717285, Accuracy: 0.0\n",
      "Loss: 2.6161231994628906, Accuracy: 0.0\n",
      "Loss: 2.940539598464966, Accuracy: 0.0\n",
      "Loss: 2.5334105491638184, Accuracy: 0.0\n",
      "Loss: 2.2088370323181152, Accuracy: 0.0\n",
      "Loss: 1.9955791234970093, Accuracy: 0.0\n",
      "Loss: 2.206495523452759, Accuracy: 0.0\n",
      "Loss: 2.9289488792419434, Accuracy: 0.0\n",
      "Loss: 2.5614700317382812, Accuracy: 0.0\n",
      "Loss: 2.0577824115753174, Accuracy: 0.5\n",
      "Loss: 2.6026034355163574, Accuracy: 0.0\n",
      "Loss: 2.065002202987671, Accuracy: 0.0\n",
      "Loss: 2.71480655670166, Accuracy: 0.0\n",
      "Loss: 2.744630813598633, Accuracy: 0.0\n",
      "Loss: 2.0259084701538086, Accuracy: 0.0\n",
      "Loss: 2.2099571228027344, Accuracy: 0.0\n",
      "Loss: 1.8818755149841309, Accuracy: 0.5\n",
      "Loss: 2.1299450397491455, Accuracy: 0.0\n",
      "Loss: 2.0326292514801025, Accuracy: 0.5\n",
      "Loss: 1.8602235317230225, Accuracy: 0.5\n",
      "Loss: 1.8490575551986694, Accuracy: 0.5\n",
      "Loss: 1.574315071105957, Accuracy: 1.0\n",
      "Loss: 1.643852710723877, Accuracy: 1.0\n",
      "Loss: 1.6363275051116943, Accuracy: 0.5\n",
      "Loss: 2.486480474472046, Accuracy: 0.0\n",
      "Loss: 2.1102211475372314, Accuracy: 0.5\n",
      "Loss: 2.066204071044922, Accuracy: 0.0\n",
      "Loss: 2.025174379348755, Accuracy: 0.5\n",
      "Loss: 1.767404317855835, Accuracy: 0.5\n",
      "Loss: 1.2782058715820312, Accuracy: 0.5\n",
      "Loss: 1.3179504871368408, Accuracy: 0.5\n",
      "Loss: 1.8800963163375854, Accuracy: 0.0\n",
      "Loss: 1.129705786705017, Accuracy: 0.5\n",
      "Loss: 2.2642242908477783, Accuracy: 0.5\n",
      "Loss: 1.5290186405181885, Accuracy: 0.5\n",
      "Loss: 2.3777124881744385, Accuracy: 0.5\n",
      "Loss: 1.119842529296875, Accuracy: 0.5\n",
      "Loss: 1.732175588607788, Accuracy: 0.5\n",
      "Loss: 1.5523773431777954, Accuracy: 0.5\n",
      "Loss: 2.2261648178100586, Accuracy: 0.5\n",
      "Loss: 0.9768139123916626, Accuracy: 1.0\n",
      "Loss: 0.8295454382896423, Accuracy: 1.0\n",
      "Loss: 0.42792606353759766, Accuracy: 1.0\n",
      "Loss: 0.31839296221733093, Accuracy: 1.0\n",
      "Loss: 2.064408302307129, Accuracy: 0.0\n",
      "Loss: 1.6136306524276733, Accuracy: 0.5\n",
      "Loss: 1.6434063911437988, Accuracy: 0.5\n",
      "Loss: 1.4083179235458374, Accuracy: 0.0\n",
      "Loss: 0.9563604593276978, Accuracy: 1.0\n",
      "Loss: 1.647004246711731, Accuracy: 0.5\n",
      "Loss: 0.5289758443832397, Accuracy: 1.0\n",
      "Loss: 1.3677576780319214, Accuracy: 0.5\n",
      "Loss: 0.9714406728744507, Accuracy: 1.0\n",
      "Loss: 0.3609084486961365, Accuracy: 1.0\n",
      "Loss: 0.2131933569908142, Accuracy: 1.0\n",
      "Loss: 0.8087910413742065, Accuracy: 1.0\n",
      "Loss: 0.537472128868103, Accuracy: 1.0\n",
      "Loss: 1.5998551845550537, Accuracy: 0.5\n",
      "Loss: 1.9398666620254517, Accuracy: 0.0\n",
      "Loss: 1.5257420539855957, Accuracy: 0.0\n",
      "Loss: 0.7575809359550476, Accuracy: 1.0\n",
      "Loss: 0.47434374690055847, Accuracy: 1.0\n",
      "Loss: 0.10844667255878448, Accuracy: 1.0\n",
      "Loss: 0.00274446583352983, Accuracy: 1.0\n",
      "Loss: 0.3574233055114746, Accuracy: 1.0\n",
      "Loss: 0.9299228191375732, Accuracy: 1.0\n",
      "Loss: 0.3732270300388336, Accuracy: 1.0\n",
      "Loss: 0.39043188095092773, Accuracy: 1.0\n",
      "Loss: 2.7004337310791016, Accuracy: 0.0\n",
      "Loss: 2.007486343383789, Accuracy: 0.0\n",
      "Loss: 1.9210118055343628, Accuracy: 0.5\n",
      "Loss: 1.7030187845230103, Accuracy: 0.5\n",
      "Loss: 1.6030545234680176, Accuracy: 0.5\n",
      "Loss: 0.5718703866004944, Accuracy: 1.0\n",
      "Loss: 0.5549739599227905, Accuracy: 1.0\n",
      "Loss: 1.1967275142669678, Accuracy: 0.5\n",
      "Loss: 0.06934450566768646, Accuracy: 1.0\n",
      "Loss: 1.1388983726501465, Accuracy: 0.5\n",
      "Loss: 0.30426254868507385, Accuracy: 1.0\n",
      "Loss: 1.3572160005569458, Accuracy: 0.5\n",
      "Loss: 1.9143427610397339, Accuracy: 0.0\n",
      "Loss: 2.3828985691070557, Accuracy: 0.0\n",
      "Loss: 2.2069475650787354, Accuracy: 0.0\n",
      "Loss: 2.324505567550659, Accuracy: 0.5\n",
      "Loss: 1.5516438484191895, Accuracy: 0.0\n",
      "Loss: 0.47639939188957214, Accuracy: 1.0\n",
      "Loss: 1.8958053588867188, Accuracy: 0.0\n",
      "Loss: 1.464787244796753, Accuracy: 0.5\n",
      "Loss: 1.0021740198135376, Accuracy: 0.5\n",
      "Loss: 1.3671513795852661, Accuracy: 0.5\n",
      "Loss: 2.572284460067749, Accuracy: 0.0\n",
      "Loss: 0.7900545001029968, Accuracy: 1.0\n",
      "Loss: 1.802031397819519, Accuracy: 0.5\n",
      "Loss: 1.4550541639328003, Accuracy: 0.5\n",
      "Loss: 0.26149579882621765, Accuracy: 1.0\n",
      "Loss: 0.8200621604919434, Accuracy: 1.0\n",
      "Loss: 2.310464859008789, Accuracy: 0.0\n",
      "Loss: 1.2503459453582764, Accuracy: 0.5\n",
      "Loss: 2.5117383003234863, Accuracy: 0.0\n",
      "Loss: 0.2810141444206238, Accuracy: 1.0\n",
      "Loss: 0.31592482328414917, Accuracy: 1.0\n",
      "Loss: 2.305968761444092, Accuracy: 0.0\n",
      "Loss: 1.1491661071777344, Accuracy: 0.5\n",
      "Loss: 1.7950807809829712, Accuracy: 0.0\n",
      "Loss: 1.9092957973480225, Accuracy: 0.5\n",
      "Loss: 1.2149465084075928, Accuracy: 0.5\n",
      "Loss: 1.419990062713623, Accuracy: 0.5\n",
      "Loss: 2.0940704345703125, Accuracy: 0.0\n",
      "Loss: 0.7199214696884155, Accuracy: 1.0\n",
      "Loss: 3.2913129329681396, Accuracy: 0.0\n",
      "Loss: 2.2549524307250977, Accuracy: 0.0\n",
      "Loss: 2.1517820358276367, Accuracy: 0.0\n",
      "Loss: 0.4138135612010956, Accuracy: 1.0\n",
      "Loss: 1.406838059425354, Accuracy: 0.5\n",
      "Loss: 2.5515246391296387, Accuracy: 0.0\n",
      "Loss: 1.7891795635223389, Accuracy: 0.5\n",
      "Loss: 1.865221381187439, Accuracy: 0.0\n",
      "Loss: 1.3494503498077393, Accuracy: 1.0\n",
      "Loss: 2.1689505577087402, Accuracy: 0.5\n",
      "Loss: 0.7839123606681824, Accuracy: 1.0\n",
      "Loss: 1.8162814378738403, Accuracy: 0.0\n",
      "Loss: 1.3412888050079346, Accuracy: 1.0\n",
      "Loss: 2.3216516971588135, Accuracy: 0.5\n",
      "Loss: 1.900006890296936, Accuracy: 0.5\n",
      "Loss: 1.6826097965240479, Accuracy: 0.5\n",
      "Loss: 1.2923049926757812, Accuracy: 0.5\n",
      "Loss: 1.673476219177246, Accuracy: 0.5\n",
      "Loss: 1.7519463300704956, Accuracy: 0.5\n",
      "Loss: 0.8982429504394531, Accuracy: 1.0\n",
      "Loss: 0.16461841762065887, Accuracy: 1.0\n",
      "Loss: 1.012865662574768, Accuracy: 0.5\n",
      "Loss: 1.3372039794921875, Accuracy: 0.5\n",
      "Loss: 0.555493950843811, Accuracy: 1.0\n",
      "Loss: 1.1891971826553345, Accuracy: 0.5\n",
      "Loss: 1.5033193826675415, Accuracy: 0.5\n",
      "Loss: 1.3665608167648315, Accuracy: 0.5\n",
      "Loss: 0.9952213168144226, Accuracy: 0.5\n",
      "Loss: 2.0920350551605225, Accuracy: 0.5\n",
      "Loss: 1.9813270568847656, Accuracy: 0.0\n",
      "Loss: 0.4887390732765198, Accuracy: 1.0\n",
      "Loss: 1.111476182937622, Accuracy: 0.0\n",
      "Loss: 1.0556856393814087, Accuracy: 0.5\n",
      "Loss: 0.16812223196029663, Accuracy: 1.0\n",
      "Loss: 0.7365379929542542, Accuracy: 0.5\n",
      "Loss: 2.622121810913086, Accuracy: 0.0\n",
      "Loss: 0.44416001439094543, Accuracy: 1.0\n",
      "Loss: 1.0081356763839722, Accuracy: 0.5\n",
      "Loss: 0.37879279255867004, Accuracy: 1.0\n",
      "Loss: 1.2510457038879395, Accuracy: 0.5\n",
      "Loss: 0.8312473297119141, Accuracy: 0.5\n",
      "Loss: 3.2150254249572754, Accuracy: 0.0\n",
      "Loss: 0.8548450469970703, Accuracy: 0.5\n",
      "Loss: 0.9374821782112122, Accuracy: 0.5\n",
      "Loss: 0.9744730591773987, Accuracy: 0.5\n",
      "Loss: 1.5053637027740479, Accuracy: 0.5\n",
      "Loss: 0.15675535798072815, Accuracy: 1.0\n",
      "Loss: 1.6240568161010742, Accuracy: 0.0\n",
      "Loss: 2.9627749919891357, Accuracy: 0.0\n",
      "Loss: 1.837378740310669, Accuracy: 0.5\n",
      "Loss: 1.022026538848877, Accuracy: 0.5\n",
      "Loss: 2.1885528564453125, Accuracy: 0.5\n",
      "Loss: 0.5844552516937256, Accuracy: 1.0\n",
      "Loss: 1.192259430885315, Accuracy: 0.5\n",
      "Loss: 0.42720767855644226, Accuracy: 1.0\n",
      "Loss: 0.2836681604385376, Accuracy: 1.0\n",
      "Loss: 1.327546238899231, Accuracy: 0.5\n",
      "Loss: 2.3550615310668945, Accuracy: 0.0\n",
      "Loss: 0.3728417754173279, Accuracy: 1.0\n",
      "Loss: 1.0763497352600098, Accuracy: 0.5\n",
      "Loss: 0.8782426118850708, Accuracy: 0.5\n",
      "Loss: 1.3308417797088623, Accuracy: 0.0\n",
      "Loss: 0.8975362181663513, Accuracy: 0.5\n",
      "Loss: 0.8350964188575745, Accuracy: 1.0\n",
      "Loss: 0.4047393202781677, Accuracy: 1.0\n",
      "Loss: 0.9051313996315002, Accuracy: 0.5\n",
      "Loss: 0.7912030220031738, Accuracy: 1.0\n",
      "Loss: 0.4272390604019165, Accuracy: 0.5\n",
      "Loss: 1.0716586112976074, Accuracy: 0.5\n",
      "Loss: 0.35144203901290894, Accuracy: 1.0\n",
      "Loss: 0.29098159074783325, Accuracy: 1.0\n",
      "Loss: 0.24683250486850739, Accuracy: 1.0\n",
      "Loss: 1.382304072380066, Accuracy: 0.5\n",
      "Loss: 0.504714846611023, Accuracy: 0.5\n",
      "Loss: 0.34779536724090576, Accuracy: 1.0\n",
      "Loss: 0.7911877036094666, Accuracy: 0.5\n",
      "Loss: 0.08017197251319885, Accuracy: 1.0\n",
      "Loss: 0.12877808511257172, Accuracy: 1.0\n",
      "Loss: 0.09575150907039642, Accuracy: 1.0\n",
      "Loss: 0.9690700173377991, Accuracy: 0.5\n",
      "Loss: 0.1373514086008072, Accuracy: 1.0\n",
      "Loss: 0.011229477822780609, Accuracy: 1.0\n",
      "Loss: 0.5869434475898743, Accuracy: 1.0\n",
      "Loss: 0.2576599419116974, Accuracy: 1.0\n",
      "Loss: 0.11322183907032013, Accuracy: 1.0\n",
      "Loss: 0.037683188915252686, Accuracy: 1.0\n",
      "Loss: 0.11797216534614563, Accuracy: 1.0\n",
      "Loss: 0.030143029987812042, Accuracy: 1.0\n",
      "Loss: 0.0027523210737854242, Accuracy: 1.0\n",
      "Loss: 0.0791068822145462, Accuracy: 1.0\n",
      "Loss: 4.955039978027344, Accuracy: 0.0\n",
      "Loss: 0.1744435727596283, Accuracy: 1.0\n",
      "Loss: 1.1177202463150024, Accuracy: 0.5\n",
      "Loss: 0.3689171373844147, Accuracy: 1.0\n",
      "Loss: 2.0532684326171875, Accuracy: 0.0\n",
      "Loss: 0.08954071998596191, Accuracy: 1.0\n",
      "Loss: 0.0804310292005539, Accuracy: 1.0\n",
      "Loss: 0.2789786756038666, Accuracy: 1.0\n",
      "Loss: 1.2229541540145874, Accuracy: 0.5\n",
      "Loss: 2.284799814224243, Accuracy: 0.0\n",
      "Loss: 0.05265882611274719, Accuracy: 1.0\n",
      "Loss: 0.48235782980918884, Accuracy: 0.5\n",
      "Loss: 0.006686929613351822, Accuracy: 1.0\n",
      "Loss: 0.7046226263046265, Accuracy: 0.5\n",
      "Loss: 2.511706590652466, Accuracy: 0.5\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebe37ee9dfc4b43b9cc1494fd8021fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.089705228805542, Accuracy: 0.5\n",
      "Loss: 0.007632815279066563, Accuracy: 1.0\n",
      "Loss: 0.07831308245658875, Accuracy: 1.0\n",
      "Loss: 0.6276270747184753, Accuracy: 0.5\n",
      "Loss: 2.671706199645996, Accuracy: 0.5\n",
      "Loss: 0.5211066603660583, Accuracy: 0.5\n",
      "Loss: 1.8519608974456787, Accuracy: 0.0\n",
      "Loss: 0.42271697521209717, Accuracy: 1.0\n",
      "Loss: 1.0217959880828857, Accuracy: 0.5\n",
      "Loss: 0.15278173983097076, Accuracy: 1.0\n",
      "Loss: 0.04442048817873001, Accuracy: 1.0\n",
      "Loss: 0.3616112172603607, Accuracy: 1.0\n",
      "Loss: 0.45234644412994385, Accuracy: 1.0\n",
      "Loss: 1.0401544570922852, Accuracy: 0.5\n",
      "Loss: 1.8183624744415283, Accuracy: 0.0\n",
      "Loss: 0.5927532315254211, Accuracy: 1.0\n",
      "Loss: 0.11321651935577393, Accuracy: 1.0\n",
      "Loss: 0.054742567241191864, Accuracy: 1.0\n",
      "Loss: 0.11891348659992218, Accuracy: 1.0\n",
      "Loss: 0.031357161700725555, Accuracy: 1.0\n",
      "Loss: 0.358981192111969, Accuracy: 1.0\n",
      "Loss: 0.1740778088569641, Accuracy: 1.0\n",
      "Loss: 0.5239387154579163, Accuracy: 1.0\n",
      "Loss: 0.6655173897743225, Accuracy: 0.5\n",
      "Loss: 1.472339391708374, Accuracy: 0.5\n",
      "Loss: 1.4293630123138428, Accuracy: 0.5\n",
      "Loss: 0.2822127640247345, Accuracy: 1.0\n",
      "Loss: 0.5606576800346375, Accuracy: 1.0\n",
      "Loss: 0.05851837247610092, Accuracy: 1.0\n",
      "Loss: 0.1935131847858429, Accuracy: 1.0\n",
      "Loss: 0.11937282234430313, Accuracy: 1.0\n",
      "Loss: 0.32489046454429626, Accuracy: 1.0\n",
      "Loss: 1.608951449394226, Accuracy: 0.0\n",
      "Loss: 0.4712791442871094, Accuracy: 1.0\n",
      "Loss: 0.16921934485435486, Accuracy: 1.0\n",
      "Loss: 0.027522176504135132, Accuracy: 1.0\n",
      "Loss: 0.7340244054794312, Accuracy: 1.0\n",
      "Loss: 0.08715903013944626, Accuracy: 1.0\n",
      "Loss: 0.10742422938346863, Accuracy: 1.0\n",
      "Loss: 0.49740517139434814, Accuracy: 1.0\n",
      "Loss: 3.196852684020996, Accuracy: 0.5\n",
      "Loss: 0.17543908953666687, Accuracy: 1.0\n",
      "Loss: 0.6490471959114075, Accuracy: 0.5\n",
      "Loss: 0.02515278197824955, Accuracy: 1.0\n",
      "Loss: 0.0737200528383255, Accuracy: 1.0\n",
      "Loss: 0.03888595849275589, Accuracy: 1.0\n",
      "Loss: 0.14643770456314087, Accuracy: 1.0\n",
      "Loss: 1.1734932661056519, Accuracy: 0.5\n",
      "Loss: 0.10820388793945312, Accuracy: 1.0\n",
      "Loss: 0.08930685371160507, Accuracy: 1.0\n",
      "Loss: 0.051964521408081055, Accuracy: 1.0\n",
      "Loss: 0.002975544659420848, Accuracy: 1.0\n",
      "Loss: 0.011002221144735813, Accuracy: 1.0\n",
      "Loss: 0.029748037457466125, Accuracy: 1.0\n",
      "Loss: 0.010800546035170555, Accuracy: 1.0\n",
      "Loss: 0.016957947984337807, Accuracy: 1.0\n",
      "Loss: 0.12277931720018387, Accuracy: 1.0\n",
      "Loss: 0.07794898003339767, Accuracy: 1.0\n",
      "Loss: 1.1829676628112793, Accuracy: 0.5\n",
      "Loss: 0.15567250549793243, Accuracy: 1.0\n",
      "Loss: 2.4896624088287354, Accuracy: 0.0\n",
      "Loss: 0.4982730746269226, Accuracy: 1.0\n",
      "Loss: 0.022636333480477333, Accuracy: 1.0\n",
      "Loss: 0.08174779266119003, Accuracy: 1.0\n",
      "Loss: 0.764854907989502, Accuracy: 0.5\n",
      "Loss: 0.1367422491312027, Accuracy: 1.0\n",
      "Loss: 0.4247164726257324, Accuracy: 1.0\n",
      "Loss: 0.5364066958427429, Accuracy: 0.5\n",
      "Loss: 0.08477383106946945, Accuracy: 1.0\n",
      "Loss: 0.24501749873161316, Accuracy: 1.0\n",
      "Loss: 0.006926055531948805, Accuracy: 1.0\n",
      "Loss: 0.13098502159118652, Accuracy: 1.0\n",
      "Loss: 0.516503095626831, Accuracy: 0.5\n",
      "Loss: 1.231292724609375, Accuracy: 0.5\n",
      "Loss: 0.04795238375663757, Accuracy: 1.0\n",
      "Loss: 0.014385453425347805, Accuracy: 1.0\n",
      "Loss: 2.5272433757781982, Accuracy: 0.5\n",
      "Loss: 0.05238816514611244, Accuracy: 1.0\n",
      "Loss: 0.2938063144683838, Accuracy: 1.0\n",
      "Loss: 0.023282930254936218, Accuracy: 1.0\n",
      "Loss: 0.03206676244735718, Accuracy: 1.0\n",
      "Loss: 0.34824979305267334, Accuracy: 1.0\n",
      "Loss: 0.002013014629483223, Accuracy: 1.0\n",
      "Loss: 0.0053204759024083614, Accuracy: 1.0\n",
      "Loss: 0.02325165644288063, Accuracy: 1.0\n",
      "Loss: 0.015340585261583328, Accuracy: 1.0\n",
      "Loss: 0.1581164002418518, Accuracy: 1.0\n",
      "Loss: 0.026722900569438934, Accuracy: 1.0\n",
      "Loss: 0.12052597105503082, Accuracy: 1.0\n",
      "Loss: 0.004276223015040159, Accuracy: 1.0\n",
      "Loss: 1.5077921152114868, Accuracy: 0.5\n",
      "Loss: 0.34439077973365784, Accuracy: 1.0\n",
      "Loss: 0.08524906635284424, Accuracy: 1.0\n",
      "Loss: 2.2063355445861816, Accuracy: 0.5\n",
      "Loss: 0.17062142491340637, Accuracy: 1.0\n",
      "Loss: 0.001008171821013093, Accuracy: 1.0\n",
      "Loss: 0.3732887804508209, Accuracy: 0.5\n",
      "Loss: 0.223886638879776, Accuracy: 1.0\n",
      "Loss: 0.0766073688864708, Accuracy: 1.0\n",
      "Loss: 0.34364819526672363, Accuracy: 1.0\n",
      "Loss: 0.007510274648666382, Accuracy: 1.0\n",
      "Loss: 1.976511001586914, Accuracy: 0.0\n",
      "Loss: 0.014192486181855202, Accuracy: 1.0\n",
      "Loss: 0.027847198769450188, Accuracy: 1.0\n",
      "Loss: 0.23347638547420502, Accuracy: 1.0\n",
      "Loss: 0.03398411348462105, Accuracy: 1.0\n",
      "Loss: 0.0899120569229126, Accuracy: 1.0\n",
      "Loss: 1.5817780494689941, Accuracy: 0.5\n",
      "Loss: 0.139584019780159, Accuracy: 1.0\n",
      "Loss: 0.497327595949173, Accuracy: 1.0\n",
      "Loss: 0.09176203608512878, Accuracy: 1.0\n",
      "Loss: 0.013750559650361538, Accuracy: 1.0\n",
      "Loss: 0.32341158390045166, Accuracy: 1.0\n",
      "Loss: 1.4186526536941528, Accuracy: 0.5\n",
      "Loss: 0.38043689727783203, Accuracy: 1.0\n",
      "Loss: 0.3474270701408386, Accuracy: 1.0\n",
      "Loss: 0.43932434916496277, Accuracy: 1.0\n",
      "Loss: 2.6450350284576416, Accuracy: 0.0\n",
      "Loss: 0.7075896859169006, Accuracy: 0.5\n",
      "Loss: 0.3907748758792877, Accuracy: 1.0\n",
      "Loss: 0.7641009092330933, Accuracy: 0.5\n",
      "Loss: 0.12463800609111786, Accuracy: 1.0\n",
      "Loss: 1.245652198791504, Accuracy: 0.5\n",
      "Loss: 1.0790427923202515, Accuracy: 0.5\n",
      "Loss: 2.647172212600708, Accuracy: 0.5\n",
      "Loss: 0.04154787212610245, Accuracy: 1.0\n",
      "Loss: 0.01155470497906208, Accuracy: 1.0\n",
      "Loss: 0.921421468257904, Accuracy: 0.5\n",
      "Loss: 0.53496915102005, Accuracy: 1.0\n",
      "Loss: 0.02855061925947666, Accuracy: 1.0\n",
      "Loss: 0.010821251198649406, Accuracy: 1.0\n",
      "Loss: 0.019162362441420555, Accuracy: 1.0\n",
      "Loss: 0.6541882753372192, Accuracy: 0.5\n",
      "Loss: 0.785973072052002, Accuracy: 0.5\n",
      "Loss: 0.21093516051769257, Accuracy: 1.0\n",
      "Loss: 0.45788928866386414, Accuracy: 1.0\n",
      "Loss: 0.4921123683452606, Accuracy: 0.5\n",
      "Loss: 0.34334030747413635, Accuracy: 1.0\n",
      "Loss: 0.1578080654144287, Accuracy: 1.0\n",
      "Loss: 1.0704340934753418, Accuracy: 0.5\n",
      "Loss: 0.5587734580039978, Accuracy: 1.0\n",
      "Loss: 0.09289804100990295, Accuracy: 1.0\n",
      "Loss: 1.0907847881317139, Accuracy: 0.5\n",
      "Loss: 0.0063537126407027245, Accuracy: 1.0\n",
      "Loss: 0.009813353419303894, Accuracy: 1.0\n",
      "Loss: 2.3429431915283203, Accuracy: 0.5\n",
      "Loss: 0.01660679094493389, Accuracy: 1.0\n",
      "Loss: 0.08907667547464371, Accuracy: 1.0\n",
      "Loss: 0.8825068473815918, Accuracy: 0.5\n",
      "Loss: 2.576000690460205, Accuracy: 0.0\n",
      "Loss: 0.14527098834514618, Accuracy: 1.0\n",
      "Loss: 0.04379669949412346, Accuracy: 1.0\n",
      "Loss: 0.34884560108184814, Accuracy: 1.0\n",
      "Loss: 0.8086052536964417, Accuracy: 0.5\n",
      "Loss: 2.26492977142334, Accuracy: 0.0\n",
      "Loss: 1.110764741897583, Accuracy: 0.5\n",
      "Loss: 0.02450985461473465, Accuracy: 1.0\n",
      "Loss: 0.0412624217569828, Accuracy: 1.0\n",
      "Loss: 0.610428512096405, Accuracy: 0.5\n",
      "Loss: 0.514802098274231, Accuracy: 1.0\n",
      "Loss: 1.026595950126648, Accuracy: 0.5\n",
      "Loss: 0.2774752378463745, Accuracy: 1.0\n",
      "Loss: 0.7215181589126587, Accuracy: 1.0\n",
      "Loss: 0.3216712474822998, Accuracy: 1.0\n",
      "Loss: 1.7040386199951172, Accuracy: 0.0\n",
      "Loss: 1.5230354070663452, Accuracy: 0.5\n",
      "Loss: 1.1467150449752808, Accuracy: 0.5\n",
      "Loss: 1.5695664882659912, Accuracy: 0.5\n",
      "Loss: 0.9347594976425171, Accuracy: 0.5\n",
      "Loss: 0.22758916020393372, Accuracy: 1.0\n",
      "Loss: 0.3373229503631592, Accuracy: 1.0\n",
      "Loss: 0.9317206144332886, Accuracy: 0.5\n",
      "Loss: 0.17789146304130554, Accuracy: 1.0\n",
      "Loss: 0.03994377702474594, Accuracy: 1.0\n",
      "Loss: 0.07021501660346985, Accuracy: 1.0\n",
      "Loss: 0.3983345329761505, Accuracy: 0.5\n",
      "Loss: 0.13167929649353027, Accuracy: 1.0\n",
      "Loss: 0.013381012715399265, Accuracy: 1.0\n",
      "Loss: 0.40581682324409485, Accuracy: 1.0\n",
      "Loss: 0.6976187825202942, Accuracy: 1.0\n",
      "Loss: 1.1238675117492676, Accuracy: 0.5\n",
      "Loss: 0.011401647701859474, Accuracy: 1.0\n",
      "Loss: 1.666788935661316, Accuracy: 0.5\n",
      "Loss: 0.05110444873571396, Accuracy: 1.0\n",
      "Loss: 2.5912177562713623, Accuracy: 0.5\n",
      "Loss: 0.02195093408226967, Accuracy: 1.0\n",
      "Loss: 0.14984166622161865, Accuracy: 1.0\n",
      "Loss: 0.1970040649175644, Accuracy: 1.0\n",
      "Loss: 1.0420407056808472, Accuracy: 0.5\n",
      "Loss: 1.6149706840515137, Accuracy: 0.0\n",
      "Loss: 0.3025306463241577, Accuracy: 1.0\n",
      "Loss: 0.057570941746234894, Accuracy: 1.0\n",
      "Loss: 0.9637171030044556, Accuracy: 0.5\n",
      "Loss: 0.03276124224066734, Accuracy: 1.0\n",
      "Loss: 0.27997732162475586, Accuracy: 1.0\n",
      "Loss: 0.13729622960090637, Accuracy: 1.0\n",
      "Loss: 0.17786601185798645, Accuracy: 1.0\n",
      "Loss: 0.01636447198688984, Accuracy: 1.0\n",
      "Loss: 0.08535350859165192, Accuracy: 1.0\n",
      "Loss: 0.16777446866035461, Accuracy: 1.0\n",
      "Loss: 0.05114423483610153, Accuracy: 1.0\n",
      "Loss: 0.7669181823730469, Accuracy: 0.5\n",
      "Loss: 0.9873160123825073, Accuracy: 0.5\n",
      "Loss: 0.005947483703494072, Accuracy: 1.0\n",
      "Loss: 0.04682042822241783, Accuracy: 1.0\n",
      "Loss: 0.2996654510498047, Accuracy: 1.0\n",
      "Loss: 0.5527542233467102, Accuracy: 0.5\n",
      "Loss: 0.6356650590896606, Accuracy: 0.5\n",
      "Loss: 0.1830066293478012, Accuracy: 1.0\n",
      "Loss: 1.6677888631820679, Accuracy: 0.5\n",
      "Loss: 2.435386896133423, Accuracy: 0.5\n",
      "Loss: 0.09337925165891647, Accuracy: 1.0\n",
      "Loss: 0.8061951994895935, Accuracy: 0.5\n",
      "Loss: 2.8911585807800293, Accuracy: 0.5\n",
      "Loss: 2.7238693237304688, Accuracy: 0.0\n",
      "Loss: 0.14919906854629517, Accuracy: 1.0\n",
      "Loss: 0.4087323844432831, Accuracy: 1.0\n",
      "Loss: 0.08554784208536148, Accuracy: 1.0\n",
      "Loss: 0.5172021389007568, Accuracy: 1.0\n",
      "Loss: 0.13020531833171844, Accuracy: 1.0\n",
      "Loss: 0.46563535928726196, Accuracy: 1.0\n",
      "Loss: 0.009706718847155571, Accuracy: 1.0\n",
      "Loss: 0.037812069058418274, Accuracy: 1.0\n",
      "Loss: 0.6578032970428467, Accuracy: 0.5\n",
      "Loss: 0.10772208124399185, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    print(\"Epoch:\", epoch)\n",
    "    for batch in tqdm(train_dataloader):\n",
    "         # get the inputs; \n",
    "         inputs = batch[\"pixel_values\"].to(device)\n",
    "         labels = batch[\"labels\"].to(device)\n",
    "\n",
    "         # zero the parameter gradients\n",
    "         optimizer.zero_grad()\n",
    "\n",
    "         # forward + backward + optimize\n",
    "         outputs = model(inputs=inputs, labels=labels)\n",
    "         loss = outputs.loss\n",
    "         loss.backward()\n",
    "         optimizer.step()\n",
    "\n",
    "         # evaluate\n",
    "         predictions = outputs.logits.argmax(-1).cpu().detach().numpy()\n",
    "         accuracy = accuracy_score(y_true=batch[\"labels\"].numpy(), y_pred=predictions)\n",
    "         print(f\"Loss: {loss.item()}, Accuracy: {accuracy}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'perceiver.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24210/2624157814.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy = load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_metric\n",
    "\n",
    "accuracy = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0537765bf2fc455aaace975d84f81c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: {'accuracy': 0.8}\n"
     ]
    }
   ],
   "source": [
    "#model = torch.load(PATH)\n",
    "from sklearn.metrics import accuracy_score\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "      for batch in tqdm(val_dataloader):\n",
    "            # get the inputs; \n",
    "            inputs = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(inputs=inputs, labels=labels)\n",
    "            logits = outputs.logits \n",
    "            predictions = logits.argmax(-1).cpu().detach().numpy()\n",
    "            references = batch[\"labels\"].numpy()\n",
    "            #accuracy = accuracy_score(y_true=batch[\"labels\"].numpy(), y_pred=predictions)\n",
    "            accuracy.add_batch(predictions=predictions, references=references)\n",
    "\n",
    "final_score = accuracy.compute()\n",
    "print(\"Accuracy on test set:\", final_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
